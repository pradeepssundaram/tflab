# import tensorflow as tf
# import pandas as pd
# import numpy as np
#
# def getdatafromdisk(trainfile, testfile):
#
#     train_raw=pd.read_csv(trainfile)
#     test_raw=pd.read_csv(testfile)
#     train_x = train_raw.iloc[:, 1:]
#     train_y = train_raw.iloc[:, 0]
#     test_x = test_raw.iloc[:, 1:]
#     test_y = test_raw.iloc[:, 0]
#
#     return train_x.values, train_y.values.astype(np.int8)\
#         , test_x.values, test_y.values.astype(np.int8)
#
# def return1Hot(data):
#     n_classes=len(np.unique(data))
#     retval = np.eye(n_classes)[data]
#     return retval
#
# def preparedatafornn():
#     # one hot encoding of labels
#     train_Data, train_Labels, test_Data, test_Labels = \
#         getdatafromdisk('../data/mnist_train.csv','../data/mnist_test.csv')
#     train_Labels=return1Hot(train_Labels)
#     test_Labels=return1Hot(test_Labels)
#     return train_Data, train_Labels, test_Data, test_Labels


import tensorflow as tf

# reset everything to rerun in jupyter
from os import path
import sys
sys.path.append('/media/admin1/60221789221762F8/tflab/tflab')

# config
batch_size = 100
learning_rate = 0.01
training_epochs = 500
logs_path = "/home/admin1/logs/24-mar-18"
from optimizers import ASGradientDescentOptimizer
# load mnist data set
from tensorflow.examples.tutorials.mnist import input_data

mnist = input_data.read_data_sets('MNIST_data', one_hot=True)

# input images
with tf.name_scope('input'):
    # None -> batch size can be any size, 784 -> flattened mnist image
    x = tf.placeholder(tf.float32, shape=[None, 784], name="x-input")
    # target 10 output classes
    y_ = tf.placeholder(tf.float32, shape=[None, 10], name="y-input")

# model parameters will change during training so we use tf.Variable
with tf.name_scope("weights"):
    W = tf.Variable(tf.zeros([784, 10]))

# bias
with tf.name_scope("biases"):
    b = tf.Variable(tf.zeros([10]))

# implement model
with tf.name_scope("softmax"):
    # y is our prediction
    y = tf.nn.softmax(tf.matmul(x, W) + b)

# specify cost function
with tf.name_scope('cross_entropy'):
    # this is our cost
    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y+1e-8), reduction_indices=[1]))

# specify optimizer
with tf.name_scope('train'):
    # optimizer is an "operation" which we can execute in a session
    optimizer=ASGradientDescentOptimizer
    train_op = ASGradientDescentOptimizer(learning_rate,scale=1.0001).minimize(cross_entropy)

with tf.name_scope('Accuracy'):
    # Accuracy
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

# create a summary for our cost and accuracy

tf.summary.scalar("cost", cross_entropy)
tf.summary.scalar("accuracy", accuracy)

# merge all summaries into a single "operation" which we can execute in a session
summary_op = tf.summary.merge_all()

with tf.Session() as sess:
    # variables need to be initialized before we can use them
    sess.run(tf.initialize_all_variables())

    # create log writer object
    writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())

    # perform training cycles
    for epoch in range(training_epochs):

        # number of batches in one epoch
        batch_count = int(mnist.train.num_examples / batch_size)

        for i in range(batch_count):
            batch_x, batch_y = mnist.train.next_batch(batch_size)
            a, summary = sess.run([train_op, summary_op], feed_dict={x: batch_x, y_: batch_y})
            writer.add_summary(summary, epoch * batch_count + i)

        if epoch % 5 == 0:
            print("epoch {} of {}".format(epoch, training_epochs))

    print("Accuracy: ", accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
    print("done")

